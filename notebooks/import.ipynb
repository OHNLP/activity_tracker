{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import data into database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from activity_tracker import utils\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "import pathlib\n",
    "import re\n",
    "\n",
    "# Import raw data into raw schema\n",
    "data_dir = pathlib.Path(\"../data/raw/\")\n",
    "db_path = \"../data/sqlite/activity_tracker.db\"\n",
    "mapper_path = pathlib.Path(\"../data/data_mapper.yml\")\n",
    "excel_path = pathlib.Path(\"../data/raw/MDE clinical data.xlsx\")\n",
    "excluded_files = [\n",
    "    \"fitbitCoreTemperature_merged.csv\",\n",
    "    \"fitbitSkinTemperature_merged.csv\",\n",
    "    \"weightLogInfo_merged.csv\",\n",
    "    \"mde_clinical_data.csv\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def camel_to_snake(name: str) -> str:\n",
    "    name = name.replace(\"_merged\", \"\")\n",
    "    return re.sub(r'(?<=[a-z0-9])([A-Z])', r'_\\1', name).lower()\n",
    "\n",
    "conn = sqlite3.connect(db_path)\n",
    "\n",
    "for file_path in data_dir.glob(\"*.csv\"):\n",
    "    if file_path.name in excluded_files:\n",
    "        continue\n",
    "\n",
    "    table_name = camel_to_snake(file_path.stem)\n",
    "    df = pd.read_csv(file_path)\n",
    "    try:\n",
    "        df.to_sql(table_name, conn, if_exists=\"fail\", index=False)\n",
    "        print(f\"Table {table_name} created with {len(df)} rows.\")\n",
    "    except ValueError:\n",
    "        print(f\"Skipping {table_name} â€” table already exists.\")\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a subject table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xls = pd.ExcelFile(excel_path)\n",
    "df_control = pd.read_excel(xls, sheet_name=xls.sheet_names[0])\n",
    "df_exercise = pd.read_excel(xls, sheet_name=xls.sheet_names[1])\n",
    "\n",
    "# Add group labels\n",
    "df_control[\"group\"] = \"control\"\n",
    "df_exercise[\"group\"] = \"exercise\"\n",
    "df_combined = pd.concat([df_control, df_exercise], ignore_index=True)\n",
    "\n",
    "subject_columns = [\n",
    "    \"Participant ID\", \"group\", \"Sex\", \"Age\", \"Eth\", \"Race\",\n",
    "    \"Mth Inc\", \"Educ\", \"Mari\", \"Liv Sit\"\n",
    "]\n",
    "df_subject = df_combined[subject_columns].copy()\n",
    "\n",
    "df_subject.columns = (\n",
    "    df_subject.columns.str.strip()\n",
    "    .str.lower()\n",
    "    .str.replace(\" \", \"_\")\n",
    "    .str.replace(\".\", \"_\")\n",
    ")\n",
    "\n",
    "# Rename columns\n",
    "rename_map = {\n",
    "    \"participant_id\": \"subject_id\",\n",
    "    \"eth\": \"ethnicity\",\n",
    "    \"mth_inc\": \"monthly_income\",\n",
    "    \"educ\": \"education\",\n",
    "    \"mari\": \"marital_status\",\n",
    "    \"liv_sit\": \"living_situation\"\n",
    "}\n",
    "df_subject = df_subject.rename(columns=rename_map)\n",
    "df_subject = df_subject.sort_values(by=\"subject_id\").reset_index(drop=True)\n",
    "\n",
    "data_dictionary = utils.load_data_mapper(mapper_path)\n",
    "\n",
    "# Apply data dictionary to map integer values to strings\n",
    "for column in data_dictionary:\n",
    "    if column in df_subject.columns:\n",
    "        df_subject[column] = df_subject[column].map(data_dictionary[column])\n",
    "        \n",
    "conn = sqlite3.connect(db_path)\n",
    "df_subject.to_sql(\"subject\", conn, if_exists=\"replace\", index=False)\n",
    "\n",
    "conn.commit()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subject"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a visit table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_unique_columns(cols):\n",
    "    seen = {}\n",
    "    result = []\n",
    "    for col in cols:\n",
    "        base = col\n",
    "        if base not in seen:\n",
    "            seen[base] = 1\n",
    "            result.append(base)\n",
    "        else:\n",
    "            count = seen[base]\n",
    "            new_col = f\"{base}_{count}\"\n",
    "            while new_col in seen:\n",
    "                count += 1\n",
    "                new_col = f\"{base}_{count}\"\n",
    "            seen[base] = count + 1\n",
    "            seen[new_col] = 1\n",
    "            result.append(new_col)\n",
    "    return result\n",
    "\n",
    "def sanitize_column(col):\n",
    "    base = col.split(\".\")[0]\n",
    "    # Remove anything in parentheses (and the parentheses themselves)\n",
    "    base = re.sub(r\"\\(.*?\\)\", \"\", base)\n",
    "    # Normalize spacing and other characters\n",
    "    name = \"_\".join(base.strip().split()).lower()\n",
    "    # Remove remaining special characters (slashes, dashes, percent signs)\n",
    "    name = name.replace(\"/\", \"\").replace(\"-\", \"\").replace(\"%\", \"\")\n",
    "    return name\n",
    "\n",
    "def stack_visits(df, group_label):\n",
    "    df = df.rename(columns={\"Participant ID\": \"subject_id\"})\n",
    "    visit_markers = sorted([col for col in df.columns if col.startswith(\"V\") and len(col) == 2 and col[1].isdigit()],\n",
    "                           key=lambda x: int(x[1:]))\n",
    "    \n",
    "    all_visits = []\n",
    "\n",
    "    for i, marker in enumerate(visit_markers):\n",
    "        start = df.columns.get_loc(marker) + 1\n",
    "        end = df.columns.get_loc(visit_markers[i + 1]) if i + 1 < len(visit_markers) else len(df.columns)\n",
    "        visit_cols = df.columns[start:end].tolist()\n",
    "\n",
    "        visit_df = df[[\"subject_id\"] + visit_cols].copy()\n",
    "        cleaned_cols = [sanitize_column(col) for col in visit_cols]\n",
    "        visit_df.columns = [\"subject_id\"] + make_unique_columns(cleaned_cols)\n",
    "\n",
    "        visit_df.insert(1, \"group\", group_label)\n",
    "        visit_df.insert(2, \"visit_id\", int(marker[1:]))\n",
    "\n",
    "        all_visits.append(visit_df)\n",
    "\n",
    "    return pd.concat(all_visits, ignore_index=True)\n",
    "\n",
    "# Load data\n",
    "xls = pd.ExcelFile(excel_path)\n",
    "\n",
    "df_visits_control = stack_visits(pd.read_excel(xls, sheet_name=0), \"control\")\n",
    "df_visits_exercise = stack_visits(pd.read_excel(xls, sheet_name=1), \"exercise\")\n",
    "\n",
    "ffp_cols = [\"wt_loss\", \"weak\", \"slow\", \"exhaust\", \"phys_act\"]\n",
    "for df in [df_visits_control, df_visits_exercise]:\n",
    "    df[\"ffp_score\"] = df[ffp_cols].sum(axis=1)\n",
    "    df[\"gait\"] = 4 / df[\"walk\"].replace(0, pd.NA)\n",
    "\n",
    "# Combine\n",
    "df_visits_all = pd.concat([df_visits_control, df_visits_exercise], ignore_index=True)\n",
    "df_visits_all = df_visits_all.sort_values(by=[\"subject_id\", \"visit_id\"]).reset_index(drop=True)\n",
    "\n",
    "conn = sqlite3.connect(db_path)\n",
    "df_visits_all.to_sql(\"visit\", conn, if_exists=\"replace\", index=False)\n",
    "\n",
    "conn.commit()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_visits_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Hourly data table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def camel_to_snake(name):\n",
    "    name = re.sub(r'(?<=[a-z0-9])([A-Z])', r'_\\1', name)\n",
    "    name = name.replace(\" \", \"_\").replace(\"-\", \"_\").replace(\"/\", \"_\")\n",
    "    return name.lower()\n",
    "\n",
    "query = \"\"\"\n",
    "SELECT *\n",
    "FROM fitbit_wear_time_via_hr wt\n",
    "  LEFT JOIN daily_activity da\n",
    "    ON wt.ID = da.ID AND wt.Day = da.ActivityDate\n",
    "LEFT JOIN daily_calories dc\n",
    "  ON da.ID = dc.ID AND da.ActivityDate = dc.ActivityDay\n",
    "LEFT JOIN daily_intensities di\n",
    "  ON dc.ID = di.ID AND dc.ActivityDay = di.ActivityDay\n",
    "LEFT JOIN daily_steps ds\n",
    "  ON dc.ID = ds.ID AND dc.ActivityDay = ds.ActivityDay\n",
    "LEFT JOIN fitbit_daily_sp_o2 fb\n",
    "  ON dc.ID = fb.ID AND dc.ActivityDay = fb.SleepDay\n",
    "\"\"\"\n",
    "\n",
    "conn = sqlite3.connect(db_path)\n",
    "df = pd.read_sql_query(query, conn)\n",
    "conn.close()\n",
    "\n",
    "# Column name sanitization\n",
    "df.columns = [camel_to_snake(col) for col in df.columns]\n",
    "df = df.loc[:, ~df.columns.duplicated()]\n",
    "df = df.drop(columns=[\"activity_date\", \"activity_day\", \"sleep_day\"]).rename({\"id\": \"subject_id\", \"day\": \"date\"}, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter rows\n",
    "start_col = df.columns.get_loc(\"percentage_wear_time\") + 1\n",
    "right_cols = df.columns[start_col:]\n",
    "\n",
    "# Drop rows where all right-side values are NaN\n",
    "filtered_df = df[~df[right_cols].isna().all(axis=1)].reset_index(drop=True)\n",
    "filtered_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "activity_tracker",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
